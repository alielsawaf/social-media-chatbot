from flask import Flask, request, send_file, abort
from fuzzywuzzy import fuzz
import requests
import re
import os
from datetime import datetime
import csv
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

app = Flask(__name__)

# ================== Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ==================
PAGE_ACCESS_TOKEN = "EAARosZC3fHjUBQNm1eADUNlWqXKJZAtNB4w9upKF3sLLcZCdz14diiyFFeSipgiEi4Vx1PZAvu9b46xPcHv2wjIekD8LZAhDuAqgSOcrAiqzZBXr3Unk5k269G26dSMZB1wsiCvazanjVWcgdoh8M6AzkPn4xzQUUUQ8o3XLJ0V5s7MfnZAyZAzWF3VBDvP4IWFX5050XCmWWGQZDZD"
VERIFY_TOKEN = "my_secret_token"
MENU_LINK = "https://heyzine.com/flip-book/31946f16d5.html"

FUZZY_THRESHOLD = 70
CSV_FILE = os.path.join(os.path.dirname(__file__), "failed_questions.csv")
CSV_PASSWORD = "123321"

PRICE_WORDS = [
    'Ø³Ø¹Ø±','Ø¨ÙƒØ§Ù…','ÙƒØ§Ù…','Ø¹Ø§Ù…Ù„','ØªÙƒÙ„ÙÙ‡','Ø«Ù…Ù†','Ù‚ÙŠÙ…Ø©','Ø³Ø¹Ø±Ù‡','Ø§Ù„Ø§Ø³Ø¹Ø§Ø±',
    'ÙƒÙ…','Ù‡Ù„ Ø¹Ù†Ø¯ÙƒÙ…','Ø¹Ø§ÙŠØ²','Ù…Ù† ÙØ¶Ù„Ùƒ','Ù„Ùˆ Ø³Ù…Ø­Øª','Ø­Ø§Ø¨Ø¨','Ø¹Ø§ÙŠØ²Ù‡','Ø§Ø±ÙŠØ¯'
]
GENERAL_TRIGGERS = [
    'Ù…Ù†ÙŠÙˆ','Ø§Ù„Ù…ÙŠÙ†ÙŠÙˆ','Ø¹Ø§ÙŠØ² Ø§Ù„Ù…Ù†ÙŠÙˆ','Ø§Ø¨Ø¹Øª Ø§Ù„Ù…Ù†ÙŠÙˆ','Ø¨ØªØ¨ÙŠØ¹Ùˆ Ø§ÙŠÙ‡','Ø§ÙŠÙ‡ Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª',
    'Ø§ÙŠÙ‡ Ø§Ù„Ù„ÙŠ Ø¹Ù†Ø¯ÙƒÙ…','Ù„Ùˆ Ø³Ù…Ø­Øª','Ø§Ø±ÙŠØ¯','Ù…Ù† ÙØ¶Ù„Ùƒ'
]
GREETINGS = [
    'Ø§Ù‡Ù„Ø§','Ø³Ù„Ø§Ù…','Ù‡Ø§ÙŠ','Ù‡Ù„Ø§','Ù…Ø±Ø­Ø¨Ø§','ØµØ¨Ø§Ø­ Ø§Ù„Ø®ÙŠØ±','Ù…Ø³Ø§Ø¡ Ø§Ù„Ø®ÙŠØ±',
    'ØµØ¨Ø§Ø­ Ø§Ù„ÙÙ„','Ù…Ø³Ø§Ø¡ Ø§Ù„ÙÙ„','ÙŠØ§ ÙÙ†Ø¯Ù…','ÙŠØ§ Ø­Ø¶Ø±Ø©','ÙŠØ§ Ø£Ø³ØªØ§Ø°'
]

# ================== ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ NLP ==================
tokenizer = AutoTokenizer.from_pretrained("aubmindlab/bert-base-arabertv02")
model = AutoModelForSequenceClassification.from_pretrained("aubmindlab/bert-base-arabertv02")

# ================== Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© ==================
def normalize_numbers(text):
    return text.translate(str.maketrans("Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù©", "0123456789"))

def clean_arabic_text(text):
    if not text: return ""
    text = normalize_numbers(text.lower().strip())
    text = re.sub(r"[Ø¥Ø£Ø¢Ø§]", "Ø§", text)
    text = re.sub(r"Ø©", "Ù‡", text)
    text = re.sub(r"Ù‰", "ÙŠ", text)
    text = re.sub(r"[^\w\s]", "", text)
    return re.sub(r"\s+", " ", text)

def clean_for_product(text):
    text = clean_arabic_text(text)
    for w in PRICE_WORDS + ['Ø¨ØªØ¨ÙŠØ¹Ùˆ','Ø¹Ù†Ø¯ÙƒÙˆ','Ø§Ø²Ø§ÙŠ','Ù…Ù…ÙƒÙ†','Ø¹Ø§ÙŠØ²']:
        text = text.replace(w, "")
    return text.strip()

def similarity(a, b):
    return fuzz.token_set_ratio(a, b)

def log_failed(question):
    file_exists = os.path.isfile(CSV_FILE)
    with open(CSV_FILE, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(["question", "created_at"])
        writer.writerow([question, datetime.now().strftime("%Y-%m-%d %H:%M:%S")])

def split_user_text(text):
    parts = re.split(r"[.ØŸ!,Ø›]", text)
    return [p.strip() for p in parts if p.strip()]

# ================== Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª ==================
PRODUCTS = [
     # Ø§Ù„Ø±Ù†Ø¬Ø©
    {'kw': ['Ø±Ù†Ø¬Ù‡ Ù…Ø¯Ø®Ù†Ù‡ Ù…Ø¨Ø·Ø±Ø®Ù‡ Ù…Ø±Ù…Ù„Ù‡', 'Ø±Ù†Ø¬Ù‡ Ù…Ø¨Ø·Ø±Ø®Ù‡', 'Ø±Ù†Ø¬Ù‡ Ù…Ø±Ù…Ù„Ù‡'], 'price': '250 EGP', 'w': '1 KG'},
    {'kw': ['Ø±Ù†Ø¬Ù‡ Ù…Ø¯Ø®Ù†Ù‡', 'Ø±Ù†Ø¬Ù‡ Ø¹Ø§Ø¯ÙŠÙ‡'], 'price': '200 EGP', 'w': '1 KG'},
    {'kw': ['Ø±Ù†Ø¬Ù‡ Ù…Ø¯Ø®Ù†Ù‡ 24 Ù‚ÙŠØ±Ø§Ø·', 'Ø±Ù†Ø¬Ù‡ 24', 'Ø±Ù†Ø¬Ù‡ Ø¹ÙŠØ§Ø± 24'], 'price': '300 EGP', 'w': '1 KG'},
    {'kw': ['Ø±Ù†Ø¬Ù‡ 24 Ù…Ø¨Ø·Ø±Ø®Ù‡', 'Ø±Ù†Ø¬Ù‡ 24 Ù…Ø±Ù…Ù„Ù‡'], 'price': '320 EGP', 'w': '1 KG'},
    {'kw': ['Ø±Ù†Ø¬Ù‡ Ù…Ù†Ø²ÙˆØ¹Ù‡ Ø§Ù„Ø§Ø­Ø´Ø§Ø¡ ÙØ§ÙƒÙŠÙˆÙ…', 'Ø±Ù†Ø¬Ù‡ ÙØ§ÙƒÙŠÙˆÙ…'], 'price': '300 EGP', 'w': '1 KG'},
    {'kw': ['Ø±Ù†Ø¬Ù‡ ÙÙŠÙ„ÙŠÙ‡ Ø¨Ø¯ÙˆÙ† Ø²ÙŠØª', 'Ø±Ù†Ø¬Ù‡ ÙÙŠÙ„ÙŠÙ‡ Ø³Ø§Ø¯Ù‡'], 'price': '600 EGP', 'w': '1 KG'},
    {'kw': ['Ø±Ù†Ø¬Ù‡ ÙÙŠÙ„ÙŠÙ‡ ØµÙˆØµ ÙÙ„ÙÙ„ ÙˆÙƒØ§ÙÙŠØ§Ø±'], 'price': '150 EGP', 'w': '200 G'},
    {'kw': ['Ø±Ù†Ø¬Ù‡ ÙÙŠÙ„ÙŠÙ‡ ÙƒØ§Ø±ÙŠ'], 'price': '250 EGP', 'w': '250 G'},
    {'kw': ['Ø±Ù†Ø¬Ù‡ ÙÙŠÙ„ÙŠÙ‡ Ø²ÙŠØª'], 'price': '250 EGP', 'w': '250 G'},
    {'kw': ['Ø±Ù†Ø¬Ù‡ ÙÙŠÙ„ÙŠÙ‡ Ù…Ø¯Ø®Ù†Ù‡'], 'price': '85 EGP', 'w': '125 G'},
    {'kw': ['ÙƒØ§ÙÙŠØ§Ø± Ø³Ø¨Ø±ÙŠØ¯', 'Ø±Ù†Ø¬Ù‡ ÙƒØ§ÙÙŠØ§Ø± Ø³Ø¨Ø±ÙŠØ¯'], 'price': '70 EGP', 'w': '200 G/130 G'},
    {'kw': ['Ø¨Ø·Ø§Ø±Ø® Ø±Ù†Ø¬Ù‡ Ø²ÙŠØª ÙƒØ§Ù…Ù„Ø©'], 'price': '250 EGP', 'w': '250 G'},
    {'kw': ['Ø¨Ø·Ø§Ø±Ø® Ø±Ù†Ø¬Ù‡ Ø¨Ø±ØªÙ‚Ø§Ù„', 'Ø¨Ø·Ø§Ø±Ø® Ù…Ù‡Ø±ÙˆØ³Ù‡'], 'price': '250 EGP', 'w': '250 G'},
    # Ø§Ù„Ù…Ø§ÙƒØ±ÙŠÙ„
    {'kw': ['Ù…Ø§ÙƒØ±ÙŠÙ„ Ù…Ø¯Ø®Ù† Ù…Ù…Ù„Ø­', 'Ù…Ø§ÙƒØ±ÙŠÙ„'], 'price': '410 EGP', 'w': '1 KG'},
    {'kw': ['Ù…Ø§ÙƒØ±ÙŠÙ„ ÙØ§ÙƒÙŠÙˆÙ…'], 'price': '460 EGP', 'w': '1 KG'},
    {'kw': ['Ù…Ø§ÙƒØ±ÙŠÙ„ ÙÙŠÙ„ÙŠÙ‡'], 'price': '800 EGP', 'w': '1 KG'},
    # Ø§Ù„ÙØ³ÙŠØ®
    {'kw': ['ÙØ³ÙŠØ® ÙÙŠÙ„ÙŠÙ‡ Ø²ÙŠØª', 'ÙØ³ÙŠØ® Ø²ÙŠØª'], 'price': '250 EGP', 'w': '250 G'},
    {'kw': ['ÙØ³ÙŠØ® ÙÙŠÙ„ÙŠÙ‡ Ø¯Ø®Ø§Ù†', 'ÙØ³ÙŠØ® Ù…Ø¯Ø®Ù†'], 'price': '250 EGP', 'w': '250 G'},
    {'kw': ['ÙØ³ÙŠØ® Ø³Ø¨Ø±ÙŠØ¯ Ø¨Ù†Ø¬Ø±'], 'price': '250 EGP', 'w': '250 G'},
    {'kw': ['ÙØ³ÙŠØ® Ø¨Ø¯ÙˆÙ† Ø¨ÙƒØªÙŠØ±ÙŠØ§', 'ÙØ³ÙŠØ® Ø·Ø¨ÙŠ'], 'price': '460 EGP', 'w': '1 KG'},
    {'kw': ['ÙØ³ÙŠØ® Ù…Ø¨Ø·Ø±Ø®'], 'price': '560 EGP', 'w': '1 KG'},
    {'kw': ['Ø´Ø±Ø§Ø¦Ø­ Ø¨ÙˆØ±ÙŠ Ù…Ø¯Ø®Ù†Ù‡', 'ÙÙŠÙ„ÙŠÙ‡ Ø¨ÙˆØ±ÙŠ Ù…Ø¯Ø®Ù†'], 'price': '810 EGP', 'w': '1 KG'},
    # Ø§Ù„Ø³Ù„Ù…ÙˆÙ†
    {'kw': ['Ø³Ù„Ù…ÙˆÙ† Ø­Ø§Ø±', 'spicy salmon'], 'price': '150 EGP', 'w': '125 G'},
    {'kw': ['Ø´Ø±Ø§Ø¦Ø­ Ø³Ù„Ù…ÙˆÙ† Ù…Ø¯Ø®Ù†Ù‡', 'Ø³Ù„Ù…ÙˆÙ† ÙÙŠÙ„ÙŠÙ‡'], 'price': '3000 EGP', 'w': '1 KG'},
    {'kw': ['Ø³ØªÙŠÙƒ Ø³Ù„Ù…ÙˆÙ†'], 'price': '1810 EGP', 'w': '1 KG'},
    {'kw': ['Ø´ÙˆØ±Ø¨Ù‡ Ø³Ù„Ù…ÙˆÙ†'], 'price': '90 EGP', 'w': '160 G'},
    # Ø§Ù„Ø¨Ø·Ø§Ø±Ø® ÙˆØ§Ù„ØªÙˆÙ†Ø©
    {'kw': ['Ø¨Ø·Ø§Ø±Ø® Ø¨ÙˆØ±ÙŠ Ù…Ù…Ù„Ø­Ù‡', 'Ø¨Ø·Ø§Ø±Ø® Ø¨ÙˆØ±ÙŠ'], 'price': '2850 EGP', 'w': '1 KG'},
    {'kw': ['ØªÙˆÙ†Ù‡ Ø­Ù…Ø±Ø§Ø¡ ÙÙŠÙ„ÙŠÙ‡', 'ØªÙˆÙ†Ù‡ Ø­Ù…Ø±Ø§'], 'price': '155 EGP', 'w': '230 G'},
    {'kw': ['ØªÙˆÙ†Ù‡ Ù‚Ø·Ø¹', ' chunks tuna'], 'price': '70 EGP', 'w': '125 G'},
    {'kw': ['ØªÙˆÙ†Ù‡ Ù…Ø·Ù‡ÙŠÙ‡'], 'price': '710 EGP', 'w': '1 KG'},
    # Ø£Ø®Ø±Ù‰
    {'kw': ['Ø§Ù†Ø´ÙˆØ¬Ù‡ ÙÙŠÙ„ÙŠÙ‡ Ø²ÙŠØª', 'Ø§Ù†Ø´ÙˆØ¬Ù‡'], 'price': '110 EGP', 'w': '125 G'},
    {'kw': ['Ø³Ø±Ø¯ÙŠÙ† Ù…Ù…Ù„Ø­'], 'price': '200 EGP', 'w': '250 G'},
    {'kw': ['Ø­Ù†Ø´Ø§Ù† Ù…Ø¯Ø®Ù†', 'ØªØ¹Ø¨Ø§Ù† Ù…Ø¯Ø®Ù†'], 'price': '810 EGP', 'w': '1 KG'}
]

FAQ = [
  {'keywords': ['Ø¯ÙˆØ¯', 'Ø·ÙÙŠÙ„ÙŠØ§Øª', 'Ø§Ù„Ø±Ù†Ø¬Ù‡ ÙÙŠÙ‡Ø§'], 'answer': "Ù„Ø§ ÙŠØ§ ÙÙ†Ø¯Ù…ØŒ Ø¯ÙŠ Ø·ÙÙŠÙ„ÙŠØ§Øª Ù…Ø´ Ø¯ÙˆØ¯. Ø¨ØªÙˆØ¬Ø¯ ÙÙŠ Ø§Ù„ØªØ¬ÙˆÙŠÙ Ø§Ù„Ø¨Ø·Ù†ÙŠ ÙˆÙ„Ø§ ØªØµÙŠØ¨ Ø§Ù„Ø¥Ù†Ø³Ø§Ù†ØŒ ÙˆØ¨ÙŠØªÙ… Ø§Ù„Ù‚Ø¶Ø§Ø¡ Ø¹Ù„ÙŠÙ‡Ø§ Ø¨Ø§Ù„ØªØ¬Ù…ÙŠØ¯ Ø¹Ù†Ø¯ -40 Ø¯Ø±Ø¬Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø£Ù…Ø§Ù†."},
   {'keywords': ['Ø³Ø§Ù†Ø¯ÙˆØªØ´Ø§Øª', 'Ø³Ù„Ø·Ø§Øª', 'ÙˆØ¬Ø¨Ø§Øª'], 'answer': "Ù…Ù†ÙŠÙˆ Ø§Ù„Ø³Ø§Ù†Ø¯ÙˆØªØ´Ø§Øª ÙˆØ§Ù„Ø³Ù„Ø·Ø§Øª ØºÙŠØ± Ù…ØªØ§Ø­ Ø­Ø§Ù„ÙŠÙ‹Ø§ ÙˆÙ„Ø§ ÙŠÙˆØ¬Ø¯ ØªÙˆØµÙŠÙ„ Ù„Ù‡Ø§."},
   {'keywords': ['Ø§ØµÙ„ÙŠÙ‡', 'Ø§Ø²Ø§ÙŠ Ø§Ø¹Ø±Ù', 'ÙƒØ±ØªÙˆÙ†Ù‡'], 'answer': "Ø±Ù†Ø¬Ø© Ø£Ø¨Ùˆ Ø§Ù„Ø³ÙŠØ¯ Ø¨ØªÙƒÙˆÙ† ÙÙŠ ÙƒØ±Ø§ØªÙŠÙ† Ù…Ø´ ØµÙ†Ø§Ø¯ÙŠÙ‚ Ø®Ø´Ø¨ØŒ ÙˆÙŠÙÙØ¶Ù‘Ù„ Ø§Ù„Ø´Ø±Ø§Ø¡ Ù…Ù† ÙØ±ÙˆØ¹Ù†Ø§ Ø§Ù„Ø±Ø³Ù…ÙŠØ©."},
   {'keywords': ['ØªÙˆØµÙŠÙ„', 'Ø¯Ù„ÙŠÙØ±ÙŠ', 'Ø´Ø­Ù†'], 'answer': "Ø§Ù„ØªÙˆØµÙŠÙ„ Ù…ØªØ§Ø­ ÙÙŠ: (Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©ØŒ Ø¨ÙˆØ±Ø³Ø¹ÙŠØ¯ØŒ Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©ØŒ Ø§Ù„ØºØ±Ø¯Ù‚Ø©). Ù„Ù„Ø·Ù„Ø¨Ø§Øª: 01212166660."},
   {'keywords': ['Ø¬Ù…Ù„Ù‡', 'ØªØ¬Ø§Ø±'], 'answer': "Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø¹Ù† Ø§Ù„Ø¬Ù…Ù„Ø© ÙÙ‚Ø·: 01211113882"},
   {'keywords': ['ØªØ³Ø®ÙŠÙ†', 'Ù†Ø§Ø±', 'Ø§Ø³Ø®Ù†'], 'answer': "Ù„Ø§ ÙŠØ§ ÙÙ†Ø¯Ù…ØŒ Ø§Ù„Ù…Ù†ØªØ¬ Ø¬Ø§Ù‡Ø² Ù„Ù„Ø£ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆÙ„Ø§ ÙŠÙØ¶Ù„ ØªØ¹Ø±Ø¶Ù‡ Ù„Ø£ÙŠ Ø­Ø±Ø§Ø±Ø©."},
   {'keywords': ['ÙØ±Ù‚', 'Ù…Ø¬Ù…Ø¯Ù‡', 'ÙØ±ÙŠØ´'], 'answer': "Ø§Ù„Ù…Ø¬Ù…Ø¯Ø©: -18 / ØµÙ„Ø§Ø­ÙŠØ© 3 Ø´Ù‡ÙˆØ±. Ø§Ù„ÙØ±ÙŠØ´: Ù…Ù† 0 Ù„Ù€ 4 / ØµÙ„Ø§Ø­ÙŠØ© Ø´Ù‡Ø±."},
   {'keywords': ['Ù…ÙˆØ§Ø¯ Ø­Ø§ÙØ¸Ù‡', 'Ø·Ø¨ÙŠØ¹ÙŠ'], 'answer': "ÙƒÙ„ Ù…Ù†ØªØ¬Ø§ØªÙ†Ø§ Ø·Ø¨ÙŠØ¹ÙŠØ© 100% ÙˆØ¨Ø¯ÙˆÙ† Ø£ÙŠ Ù…ÙˆØ§Ø¯ Ø­Ø§ÙØ¸Ø©."},
   {'keywords': ['Ù…ÙˆØ§Ø¹ÙŠØ¯', 'Ø¨ØªÙØªØ­ÙˆØ§'], 'answer': "ÙŠÙˆÙ…ÙŠÙ‹Ø§ Ù…Ù† 10 ØµØ¨Ø§Ø­Ù‹Ø§ Ø¥Ù„Ù‰ 12 Ù…Ù†ØªØµÙ Ø§Ù„Ù„ÙŠÙ„."},
   {'keywords': ['Ø´ØºÙ„', 'ØªÙˆØ¸ÙŠÙ', 'Ù…Ù†Ø¯ÙˆØ¨'], 'answer': "Ù„Ù„ÙˆØ¸Ø§Ø¦Ù Ø¨Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©: 01210188882 (ÙˆØ§ØªØ³Ø§Ø¨ + Ø§ØªØµØ§Ù„)"},
   {'keywords': ['ØªØµØ¯ÙŠØ±', 'Ø®Ø§Ø±Ø¬ Ù…ØµØ±'], 'answer': "Ù„Ù„ØªØµØ¯ÙŠØ±: 01272475555 Ø£/ Ø£Ø­Ù…Ø¯."},
   {'keywords': ['Ù…ÙˆØ§Ø±Ø¯ Ø¨Ø´Ø±ÙŠÙ‡', 'hr'], 'answer': "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù€ HR: 01200056103"},
   {'keywords': ['Ù…Ù†ÙŠÙˆ', 'Ø§Ø³Ø¹Ø§Ø±ÙƒÙ…', 'Ø¨ÙƒØ§Ù…'], 'answer': f"Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ùƒ! ØªÙØ¶Ù„ Ø§Ù„Ù…Ù†ÙŠÙˆ Ø§Ù„ÙƒØ§Ù…Ù„ Ø¨Ø§Ù„Ø£Ø³Ø¹Ø§Ø± Ù…Ù† Ù‡Ù†Ø§:\n{MENU_LINK}"}
]

# ================== ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†Øµ Ø¨Ø§Ù„Ù€ NLP ==================
def analyze_text(user_text):
    text = clean_arabic_text(user_text)
    intent = None
    product_name = None
    matches = []
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ù†ØªØ¬Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Fuzzy
    for p in PRODUCTS:
        for kw in p['kw']:
            if similarity(text, clean_arabic_text(kw)) >= FUZZY_THRESHOLD:
                matches.append(p)
                break
    
    if matches:
        intent = "ask_price"
        product_name = matches
    else:
        for item in FAQ:
            for kw in item['keywords']:
                if kw in text or similarity(text, clean_arabic_text(kw)) >= FUZZY_THRESHOLD:
                    intent = "faq"
                    product_name = item['answer']
                    break
    
    if not intent and any(w in text for w in GREETINGS):
        intent = "greeting"
    
    return intent, product_name

def get_answer(user_text):
    intent, data = analyze_text(user_text)
    
    if intent == "ask_price":
        matches = data
        if len(matches) > 1:
            quick_replies = []
            for m in matches[:10]:
                quick_replies.append({
                    "content_type": "text",
                    "title": m['kw'][0][:20],
                    "payload": f"PRODUCT_INDEX|{PRODUCTS.index(m)}"
                })
            return {"text": "Ø­Ø¶Ø±ØªÙƒ ØªÙ‚ØµØ¯ Ø£ÙŠ Ù…Ù†ØªØ¬ Ø¨Ø§Ù„Ø¸Ø¨Ø·ØŸ", "quick_replies": quick_replies}
        else:
            p = matches[0]
            return {"text": f"âœ”ï¸ {p['kw'][0]}\nğŸ’° {p['price']}\nâš–ï¸ {p['w']}", "quick_replies": None}
    
    elif intent == "faq":
        return {"text": data, "quick_replies": None}
    
    elif intent == "greeting":
        return {"text": "Ø£Ù‡Ù„Ø§Ù‹ Ø¨Ø­Ø¶Ø±ØªÙƒ ğŸ‘‹", "quick_replies": None}
    
    else:
        log_failed(user_text)
        return {"text": f"Ù…Ø´ ÙØ§Ù‡Ù… Ø­Ø¶Ø±ØªÙƒ Ù‚ÙˆÙŠ ğŸ˜…\nğŸ“– Ø§Ù„Ù…Ù†ÙŠÙˆ:\n{MENU_LINK}", "quick_replies": None}

def process_long_message(user_text):
    parts = split_user_text(user_text)
    responses = []
    for part in parts:
        ans = get_answer(part)
        if ans['text'] not in [r['text'] for r in responses]:
            responses.append(ans)
    return responses

# ================== Webhook ==================
@app.route('/webhook', methods=['GET'])
def verify():
    if request.args.get("hub.verify_token") == VERIFY_TOKEN:
        return request.args.get("hub.challenge")
    return "Verification failed", 403

@app.route('/webhook', methods=['POST'])
def webhook():
    data = request.get_json()
    if data.get("object") == "page":
        for entry in data.get("entry", []):
            for msg_event in entry.get("messaging", []):
                sender = msg_event["sender"]["id"]
                
                if "message" in msg_event and "quick_reply" in msg_event["message"]:
                    payload = msg_event["message"]["quick_reply"]["payload"]
                    if payload.startswith("PRODUCT_INDEX|"):
                        idx = int(payload.split("|")[1])
                        p = PRODUCTS[idx]
                        reply_text = f"âœ”ï¸ Ø§Ù„Ù…Ù†ØªØ¬ Ù…ØªÙˆÙØ±\nğŸ“Œ {p['kw'][0]}\nğŸ’° Ø§Ù„Ø³Ø¹Ø±: {p['price']}\nâš–ï¸ Ø§Ù„ÙˆØ²Ù†: {p['w']}"
                        send_message(sender, reply_text)
                
                elif "message" in msg_event and "text" in msg_event["message"]:
                    user_text = msg_event["message"]["text"]
                    responses = process_long_message(user_text)
                    for res in responses:
                        send_message(sender, res["text"], res.get("quick_replies"))
                    
    return "ok", 200

def send_message(user_id, text, quick_replies=None):
    url = f"https://graph.facebook.com/v12.0/me/messages?access_token={PAGE_ACCESS_TOKEN}"
    payload = {
        "recipient": {"id": user_id},
        "message": {"text": text}
    }
    if quick_replies:
        payload["message"]["quick_replies"] = quick_replies
    requests.post(url, json=payload)

# ================== ØªØ­Ù…ÙŠÙ„ CSV ==================
@app.route('/download_csv')
def download_csv():
    if request.args.get("password") != CSV_PASSWORD:
        return abort(403)
    if not os.path.isfile(CSV_FILE):
        return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ø¨Ø¹Ø¯"
    return send_file(CSV_FILE, as_attachment=True)

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 8080)))
